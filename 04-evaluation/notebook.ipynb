{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19381780",
   "metadata": {},
   "source": [
    "# Evaluating Agents\n",
    "\n",
    "ä¸Šä¸€èŠ‚ä¸­æˆ‘ä»¬ä½¿ç”¨LangGraphåˆ›å»ºäº†ç¬¬ä¸€ä¸ªagentï¼Œå¯ä»¥å¸®æˆ‘ä»¬å›å¤é‚®ä»¶ï¼ˆçœŸæ­£å›å¤çš„åŠŸèƒ½è¿˜æ²¡æœ‰å®ç°ï¼‰ï¼Œå†ç»§ç»­å®ç°æ›´å¤šåŠŸèƒ½ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆæ¥å­¦ä¹ ä¸€ä¸‹å¦‚ä½•è¯„ä¼°ï¼ˆevaluationï¼‰agentçš„æ•ˆæœã€‚\n",
    "![overview-img](img/overview_eval.png)\n",
    "\n",
    "æµ‹è¯•ç¯èŠ‚å¯¹äºä¸€ä¸ªagentèƒ½å¦éƒ¨ç½²åˆ°ç”Ÿæˆç¯å¢ƒæœ‰ç€éå¸¸é‡è¦çš„å½±å“ï¼Œåªæœ‰é€šè¿‡æµ‹è¯•ï¼Œæ‰èƒ½çŸ¥é“è¯¸å¦‚å›å¤è´¨é‡ã€Tokenæ¶ˆè€—é‡ã€å»¶è¿Ÿã€åˆ†ç±»å‡†ç¡®æ€§ç­‰ä¸€äº›åˆ—é‡åŒ–çš„æŒ‡æ ‡ã€‚\n",
    "\n",
    "æˆ‘ä»¬å°†ä½¿ç”¨ [LangSmith](https://docs.smith.langchain.com/) æ¥å®Œæˆè¿™ä¸ªä»»åŠ¡ï¼ŒLangSmith æ˜¯ LangChain å›¢é˜Ÿå¼€å‘çš„ï¼Œç”¨äºè¯„ä¼°å’Œç›‘æ§ LLM åº”ç”¨çš„å¹³å°ï¼Œå®ƒæä¾›äº†ä¸¤ç§ä¸»è¦çš„æ–¹å¼æ¥æµ‹è¯•agentã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4692ff6",
   "metadata": {},
   "source": [
    "Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcad629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\")\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7174edf6",
   "metadata": {},
   "source": [
    "## How to run Evaluations\n",
    "\n",
    "### Pytest / Vitest\n",
    "\n",
    "Pytest å’Œ Vitest åˆ†åˆ«æ˜¯ Python å’Œ JavaScript çš„å•å…ƒæµ‹è¯•æ¡†æ¶ï¼Œç”¨äºè¿è¡Œæµ‹è¯•ä»£ç å¹¶ç”Ÿæˆæµ‹è¯•æŠ¥å‘Šï¼ŒLangSmith ä¸­é›†æˆäº†è¿™äº›æ¡†æ¶ï¼Œå¯ä»¥æ–¹ä¾¿çš„å°†æµ‹è¯•æŠ¥å‘ŠåŒæ­¥åˆ° LangSmith ä¸­ã€‚åœ¨æœ¬é¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ Pytest æ¥è¿è¡Œæµ‹è¯•ä»£ç ã€‚\n",
    "\n",
    "Pytest è¯­æ³•ç®€æ´ï¼Œå¾ˆå®¹æ˜“ä¸Šæ‰‹ï¼Œè€Œä¸”ï¼Œå¯¹äºé‚£äº›æœ‰å¤æ‚é€»è¾‘ï¼Œå¾ˆéš¾é€šç”¨å½¢å¼å¤„ç†çš„æµ‹è¯•åœºæ™¯ï¼ŒPytest ä¹Ÿæä¾›äº†è¶³å¤Ÿçš„çµæ´»æ€§æ¥å¤„ç†ã€‚\n",
    "\n",
    "### LangSmith Datasets\n",
    "\n",
    "é™¤äº†å¼€å‘è¯­è¨€æœ¬èº«æ‰€æä¾›çš„å•å…ƒæµ‹è¯•æ¡†æ¶å¤–ï¼ŒLangSmith è¿˜æä¾›äº†è‡ªå·±çš„æ•°æ®é›†ï¼ˆDatasetsï¼‰ç®¡ç†åŠŸèƒ½ï¼Œä½ å¯ä»¥é€šè¿‡ LangSmith çš„ API æ¥ä½¿ç”¨è¿™äº›æ•°æ®é›†æµ‹è¯•ä½ çš„åº”ç”¨ã€‚\n",
    "* LangSmith datasets are great for teams who are collaboratively building out their test suite. \n",
    "* You can leverage production traces, annotation queues, synthetic data generation, and more, to add examples to an ever-growing golden dataset.\n",
    "* LangSmith datasets are great when you can define evaluators that can be applied to every test case in the dataset (ex. similarity, exact match accuracy, etc.)\n",
    "\n",
    "> Note: _annotation queues_ æ˜¯ä¸€ç§æ•°æ®æ ‡æ³¨ç³»ç»Ÿä½¿ç”¨çš„é˜Ÿåˆ—ï¼Œä½œç”¨æ˜¯å°†éœ€è¦æ ‡æ³¨çš„æ•°æ®æœ‰åºçš„åˆ†é…ç»™æ ‡æ³¨äººå‘˜ï¼Œå¹¶è·Ÿè¸ªç®¡ç†æ ‡æ³¨è¿›åº¦ã€è´¨é‡å’Œä¸€è‡´æ€§ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83430f9f",
   "metadata": {},
   "source": [
    "## æµ‹è¯•ç”¨ä¾‹ï¼ˆTest Casesï¼‰\n",
    "\n",
    "æµ‹è¯•æ°¸è¿œéƒ½æ˜¯ä»å®šä¹‰æµ‹è¯•ç”¨ä¾‹å¼€å§‹çš„ï¼Œè¿™ä¸€æ­¥å¾ˆé‡è¦ä¹Ÿå¾ˆæœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºä½ å¿…é¡»æ¸…æ¥šçš„çŸ¥é“ä½ çš„agentè¦åšä»€ä¹ˆï¼Œä½ æ‰èƒ½å®šä¹‰å‡ºæ­£ç¡®çš„æµ‹è¯•ç”¨ä¾‹ã€‚\n",
    "\n",
    "è¿™é‡Œäº‹å…ˆå®šä¹‰å¥½äº†ä¸€äº›æµ‹è¯•ç”¨ä¾‹ï¼Œæ¯ä¸ªç”¨ä¾‹åŒ…å«ä»¥ä¸‹å­—æ®µï¼š\n",
    "- `email_input`: è¾“å…¥çš„é‚®ä»¶å†…å®¹\n",
    "- `expected_tool_calls`: æœŸå¾…çš„å·¥å…·è°ƒç”¨ç»“æœ\n",
    "- `triage_output`: æœŸå¾…çš„åˆ†ç±»ç»“æœ\n",
    "- `response_criteria`: å›å¤çš„é‚®ä»¶å†…å®¹åº”è¯¥æ»¡è¶³çš„æ ‡å‡†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b23a151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# eval.email_dataset ä¸­å®šä¹‰å¥½äº†ä¸€ç»„æµ‹è¯•ç”¨ä¾‹\n",
    "from src.eval.email_dataset import email_inputs, expected_tool_calls, triage_outputs_list, response_criteria_list\n",
    "\n",
    "test_case_ix = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cafc873",
   "metadata": {},
   "source": [
    "ä¸‹é¢æˆ‘ä»¬é€ä¸ªæ¥æŸ¥çœ‹ä¸€ä¸‹è¿™äº›æµ‹è¯•ç”¨ä¾‹çš„å†…å®¹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9817c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email Input: <class 'dict'> {'author': 'Alice Smith <alice.smith@company.com>', 'to': 'Lance Martin <lance@company.com>', 'subject': 'Quick question about API documentation', 'email_thread': \"Hi Lance,\\n\\nI was reviewing the API documentation for the new authentication service and noticed a few endpoints seem to be missing from the specs. Could you help clarify if this was intentional or if we should update the docs?\\n\\nSpecifically, I'm looking at:\\n- /auth/refresh\\n- /auth/validate\\n\\nThanks!\\nAlice\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Email Input:\", email_inputs[test_case_ix])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f02deef",
   "metadata": {},
   "source": [
    "Email Input ä¸­åŒ…å« authorã€toã€subjectã€email_thread ç­‰ä¿¡æ¯ï¼Œagentçš„ä½œç”¨å°±æ˜¯è¦æ ¹æ®è¿™äº›ä¿¡æ¯æ¥å†³å®šè¯¥å¦‚ä½•å›å¤é‚®ä»¶ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75d1fc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Tool Calls: ['write_email', 'done']\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected Tool Calls:\", expected_tool_calls[test_case_ix])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bede8050",
   "metadata": {},
   "source": [
    "Expected Tool Calls ä¸­å­˜å‚¨äº†agentåœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­ä¾æ¬¡éœ€è¦æ‰§è¡Œçš„å·¥å…·åç§°ï¼Œåœ¨ä¸Šé¢è¿™ä¸ªç”¨ä¾‹ä¸­ï¼Œagentéœ€è¦ä¾æ¬¡è°ƒç”¨ `write_email` å’Œ `done` ä¸¤ä¸ªå·¥å…·ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f207b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triage Output: respond\n"
     ]
    }
   ],
   "source": [
    "print(\"Triage Output:\", triage_outputs_list[test_case_ix])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2c2b94",
   "metadata": {},
   "source": [
    "Triage Output æ˜¯ç”¨æ¥è¯„ä¼°åˆ†ç±»èŠ‚ç‚¹æ•ˆæœçš„ï¼Œå¯¹åº”çš„ä¸‰ç§å¯èƒ½å€¼åˆ†åˆ«æ˜¯ ignore, notify, respondã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5d92975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Criteria: \n",
      "â€¢ Send email with write_email tool call to acknowledge the question and confirm it will be investigated  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Response Criteria:\", response_criteria_list[test_case_ix])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f611954e",
   "metadata": {},
   "source": [
    "Response Criteria æ˜¯é’ˆå¯¹éœ€è¦å›å¤çš„é‚®ä»¶ï¼Œagentæ‰€æ’°å†™çš„é‚®ä»¶åº”è¯¥æ»¡è¶³ä»€ä¹ˆæ ·çš„è¦æ±‚ã€‚\n",
    "\n",
    "**é€šè¿‡ä¸Šé¢4ä¸ªæµ‹è¯•æ ‡å‡†å¯ä»¥çœ‹å‡ºï¼Œæˆ‘ä»¬çš„æµ‹è¯•æ—¢åŒ…å«ç«¯åˆ°ç«¯çš„ç»“æœæµ‹è¯•ï¼Œä¹ŸåŒ…å«ç‰¹å®šæ­¥éª¤çš„ä¸­é—´è¿‡ç¨‹æµ‹è¯•ã€‚**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466c1790",
   "metadata": {},
   "source": [
    "## Pytest æµ‹è¯•\n",
    "\n",
    "åŸºäºä¸Šé¢ä»‹ç»çš„å†…å®¹ï¼Œé¦–å…ˆæˆ‘ä»¬æ¥ä½¿ç”¨ Pytest æµ‹è¯•ä¸€ä¸‹agentå·¥å…·è°ƒç”¨çš„æ•ˆæœæ€ä¹ˆæ ·ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6451e2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "from src.eval.email_dataset import email_inputs, expected_tool_calls\n",
    "from src.utils import format_messages_string\n",
    "from src.utils import extract_tool_calls\n",
    "from src.email_assistant import email_assistant\n",
    "\n",
    "from langsmith import testing as t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80847ed5",
   "metadata": {},
   "source": [
    "`email_assistant` æ˜¯æˆ‘ä»¬ä¸ŠèŠ‚å†…å®¹æ„å»ºçš„agentï¼Œä¹Ÿæ˜¯æˆ‘ä»¬è¦æµ‹è¯•çš„å¯¹è±¡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa2eed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.langsmith\n",
    "@pytest.mark.parametrize(\n",
    "    \"email_input, expected_tool_calls\",\n",
    "    [\n",
    "        (email_inputs[0], expected_tool_calls[0]),\n",
    "        (email_inputs[3], expected_tool_calls[3]),\n",
    "    ]   \n",
    ")\n",
    "def test_email_dataset_tool_calls(email_input, expected_tool_calls):\n",
    "    \"\"\"Test if email processing contains expected tool calls.\n",
    "\n",
    "    è¿™é‡Œåªæµ‹è¯•äº†å·¥å…·æ˜¯å¦è¢«æ­£ç¡®è°ƒç”¨ï¼Œæ²¡æœ‰æµ‹è¯•è°ƒç”¨é¡ºåºã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    # Run the email assistant\n",
    "    result = email_assistant.invoke({\"email_input\": email_input})\n",
    "\n",
    "    # Extract tool calls from the result\n",
    "    extracted_tool_calls = extract_tool_calls(result[\"messages\"])\n",
    "\n",
    "    # check if all expected tool calls are in the extracted ones\n",
    "    missing_calls = [call for call in expected_tool_calls if call not in extracted_tool_calls]\n",
    "\n",
    "    t.log_outputs({\n",
    "        \"missing_calls\": missing_calls,\n",
    "        \"extracted_tool_calls\": extracted_tool_calls,\n",
    "        \"response\": format_messages_string(result[\"messages\"])\n",
    "    })\n",
    "\n",
    "    assert len(missing_calls) == 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648a76b9",
   "metadata": {},
   "source": [
    "ä¸Šè¿°ä»£ç å®Œæ•´çš„å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ Pytest å’Œ LangSmith æ¥æµ‹è¯•ä¸€ä¸ªæ™ºèƒ½ä½“ã€‚æœ‰å‡ ç‚¹å†…å®¹éœ€è¦æ³¨æ„ä¸€ä¸‹ï¼š\n",
    "- åªéœ€è¦æ·»åŠ è£…é¥°å™¨ `@pytest.mark.langsmith`ï¼Œå°±å¯ä»¥å°†æµ‹è¯•ç»“æœè‡ªåŠ¨ä¸Šä¼ åˆ° LangSmith è¿›è¡ŒæŸ¥çœ‹ï¼›\n",
    "- é€šè¿‡è£…é¥°å™¨ `@pytest.mark.parameterize`ï¼Œå¯ä»¥å°†æµ‹è¯•ç”¨ä¾‹å‚æ•°åŒ–ã€‚\n",
    "\n",
    "### Running Pytest\n",
    "\n",
    "æˆ‘ä»¬éœ€è¦å†å‘½ä»¤è¡Œä¸­è¿è¡Œä¸Šè¿°ä»£ç ï¼Œé¦–å…ˆæˆ‘ä»¬éœ€è¦å°†ä»£ç æ•´ç†åˆ° `tests/test_tools.py` æ–‡ä»¶ä¸­ï¼Œç„¶ååœ¨å‘½ä»¤è¡Œä¸­åˆ‡æ¢åˆ° `tests` ç›®å½•ä¸‹ï¼Œæ‰§è¡Œï¼š\n",
    "```bash\n",
    "LANGSMITH_TEST_SUITE='Email assistant 04: Test Tools For Interrupt'  pytest test_tools.py\n",
    "```\n",
    "å…¶ä¸­ï¼Œ`LANGSMITH_TEST_SUITE` æ˜¯ä¸€ä¸ªç¯å¢ƒå˜é‡ï¼Œç”¨äºæŒ‡å®šæµ‹è¯•æ•°æ®é›†çš„åç§°ã€‚\n",
    "\n",
    "### æŸ¥çœ‹ç»“æœ\n",
    "\n",
    "è¿è¡Œç»“æŸä¹‹åï¼Œåœ¨ LangSmith å¹³å°ï¼ˆ[https://smith.langchain.com/](https://smith.langchain.com/)ï¼‰ çš„ Datasets & Experiments é¡µé¢å¯ä»¥çœ‹åˆ°ä½ çš„æµ‹è¯•ç»“æœã€‚\n",
    "\n",
    "![langsmith_pytest.png](img/langsmith_pytest.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf08f77",
   "metadata": {},
   "source": [
    "## LangSmith Datasets æµ‹è¯•\n",
    "\n",
    "å­¦ä¹ å®Œäº†ä½¿ç”¨ Pytest æµ‹è¯•å·¥å…·è°ƒç”¨çš„ç»“æœä¹‹åï¼Œæ¥ç€å­¦ä¹ å¦‚ä½•ä½¿ç”¨ LangSmith Datasets æ¥æµ‹è¯•é‚®ä»¶åˆ†ç±»ï¼ˆtriage_routerï¼‰çš„æ•ˆæœã€‚\n",
    "\n",
    "ä¸‹å›¾å±•ç¤ºäº† LangSmith Datasets çš„å·¥ä½œæµç¨‹ï¼ŒDataset Examples ä¸­çš„ inputs ä¼šä½œä¸ºå‚æ•°ä¼ å…¥åˆ° Agent ä¸­ï¼ˆä¹Ÿå°±æ˜¯`eamil_assistant`ï¼‰ï¼Œç„¶åå°† Agent çš„è¾“å‡ºå’Œ reference outputs é€šè¿‡ Test Function è¿›è¡Œæ¯”è¾ƒï¼Œæœ€åè¾“å…¥æµ‹è¯•ç»“æœã€‚\n",
    "\n",
    "![LangSmith Datasets æµ‹è¯•æµç¨‹](img/eval_detail.png)\n",
    "\n",
    "LangSmith æä¾›äº†å¯¹åº”çš„ SDK æ¥å®Œæˆè¿™äº›æ“ä½œã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a67f1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "# Initialize LangSmith client\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7395a1e",
   "metadata": {},
   "source": [
    "### å®šä¹‰ Dataset\n",
    "\n",
    "è¦ä½¿ç”¨ LangSmith Datasetsï¼Œé¦–å…ˆéœ€è¦å®šä¹‰ä¸€ä¸ª Datasetã€‚å¹¶å°†è¿™ä¸ª Dataset ä¸Šä¼ åˆ° LangSmith æœåŠ¡ä¸Šã€‚\n",
    "\n",
    "æˆ‘ä»¬å°†æå‰åœ¨ `src/eval/email_dataset.py` ä¸­å®šä¹‰å¥½çš„ä¸€ç»„æµ‹è¯•ç”¨ä¾‹ä¸Šä¼ åˆ° LangSmith ä¸Šã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "590d8eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.eval.email_dataset import examples_triage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc8ea44",
   "metadata": {},
   "source": [
    "æ¯ä¸ªç”¨ä¾‹åŒ…å«é‚®ä»¶è¾“å…¥å’Œæ­£ç¡®çš„åˆ†ç±»ç»“æœï¼š\n",
    "```python\n",
    "examples_triage = [\n",
    "  {\n",
    "      \"inputs\": {\"email_input\": email_input_1},\n",
    "      \"outputs\": {\"classification\": triage_output_1},   # NOTE: This becomes the reference_output in the created dataset\n",
    "  }, ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8153b78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Example Input (inputs): {'email_input': {'author': 'Alice Smith <alice.smith@company.com>', 'to': 'Lance Martin <lance@company.com>', 'subject': 'Quick question about API documentation', 'email_thread': \"Hi Lance,\\n\\nI was reviewing the API documentation for the new authentication service and noticed a few endpoints seem to be missing from the specs. Could you help clarify if this was intentional or if we should update the docs?\\n\\nSpecifically, I'm looking at:\\n- /auth/refresh\\n- /auth/validate\\n\\nThanks!\\nAlice\"}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Example Input (inputs):\", examples_triage[0]['inputs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43b505ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Example Reference Output (reference_outputs): {'classification': 'respond'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Example Reference Output (reference_outputs):\", examples_triage[0]['outputs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065a5451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset name\n",
    "dataset_name = \"04 E-Mail Triage Evaluation\"\n",
    "\n",
    "# If the dataset doesn't exist, create it\n",
    "if not client.has_dataset(dataset_name=dataset_name):\n",
    "    dataset = client.create_dataset(\n",
    "        dataset_name = dataset_name,\n",
    "        description = \"A dataset of e-mails and their triage decisions.\"\n",
    "    )\n",
    "\n",
    "    # Add examples to the dataset\n",
    "    client.create_examples(dataset_id=dataset.id, examples=examples_triage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deb66af",
   "metadata": {},
   "source": [
    "ä¸Šè¿°ä»£ç æ‰§è¡Œå®Œåï¼Œå¯ä»¥åœ¨ LangSmith å¹³å°ä¸Šçœ‹åˆ°æˆ‘ä»¬åˆ›å»ºçš„ Datasetã€‚æ¯ä¸ª Example éƒ½åŒ…å«ä¸€ä¸ª input å’Œ reference outputã€‚\n",
    "\n",
    "![LangSmith Dataset](./img/04_langsmith_dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de108cb",
   "metadata": {},
   "source": [
    "### ç›®æ ‡å‡½æ•°ï¼ˆTarget Functionï¼‰\n",
    "\n",
    "ç›®æ ‡å‡½æ•°å°±æ˜¯è¦æµ‹è¯•çš„å‡½æ•°ï¼Œè¿™é‡Œéœ€è¦æµ‹è¯• triage_router çš„æ•ˆæœæ€ä¹ˆæ ·ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦å†™ä¸€ä¸ªç›®æ ‡å‡½æ•°ï¼Œå°†é‚®ä»¶è¾“å…¥åˆ° triage_router ä¸­ï¼Œç„¶åè·å–å…¶è¾“å‡ºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c167a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_email_assistant(input: dict) -> dict:\n",
    "    \"\"\"Process an email through the workflow-based email assistant.\"\"\"\n",
    "\n",
    "    response = email_assistant.nodes['triage_router'].invoke({\"email_input\": input[\"email_input\"]})\n",
    "    return {\"classification_decision\": response.update['classification_decision']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7974f0e7",
   "metadata": {},
   "source": [
    "åœ¨å…·ä½“æ‰§è¡Œçš„æ—¶å€™ï¼ŒLangSmith çš„ API ä¼šå°† dataset ä¸­çš„æ¯ä¸€æ¡æ•°æ®ï¼Œå°†å…¶ `inputs` å­—æ®µå–å‡ºï¼Œè°ƒç”¨ `target_email_assistant` å‡½æ•°ï¼Œç„¶åå°†å‡½æ•°çš„è¾“å‡ºä¸ `reference_outputs` è¿›è¡Œæ¯”è¾ƒï¼Œå¾—åˆ°ä¸€ä¸ªè¯„ä¼°ç»“æœã€‚\n",
    "\n",
    "ä»£ç ä¸­æœ‰ä¸¤ç‚¹è¯´æ˜ï¼š\n",
    "- `email_assistant.nodes` å¯ä»¥è®¿é—®åˆ° graph ä¸­æ¯ä¸€ä¸ªèŠ‚ç‚¹ï¼›\n",
    "- `triage_router` è¿”å›çš„æ˜¯ä¸€ä¸ª Command å¯¹è±¡ï¼ŒåŒ…å« `update` å’Œ `goto` ä¸¤ä¸ªå†…å®¹ï¼Œè¿™é‡Œæˆ‘ä»¬åªå…³å¿ƒ `update`ï¼Œå³å¯¹ State çš„æ›´æ–°å†…å®¹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7db62f8",
   "metadata": {},
   "source": [
    "### è¯„ä¼°å‡½æ•°ï¼ˆEvaluator Functionï¼‰\n",
    "\n",
    "å¯¹ç›®æ ‡å‡½æ•°çš„è¾“å‡ºç»“æœï¼Œåº”è¯¥æ€ä¹ˆè¯„ä»·å…¶å¥½åå‘¢ï¼Ÿç°åœ¨æˆ‘ä»¬å·²ç»æœ‰äº†ï¼š\n",
    "* Reference outputs: `\"reference_outputs\": {\"classification\": triage_output_1} ...`\n",
    "* Agent outputs: `\"outputs\": {\"classification_decision\": agent_output_1} ...`\n",
    "\n",
    "æˆ‘ä»¬å¸Œæœ›è¯„ä¼° agent's output å’Œ reference output ä¹‹é—´çš„å·®å¼‚ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†å®šä¹‰ä¸€ä¸ªè¯„ä¼°å‡½æ•°æ¥æ¯”è¾ƒä»–ä»¬çš„ç»“æœã€‚è¿™ä¸ªå‡½æ•°ä¸­ï¼Œå…¥å‚é»˜è®¤ä¸ºï¼š\n",
    "- `outputs`: agent's output\n",
    "- `reference_outputs`: reference output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7789ad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_evaluator(outputs: dict, reference_outputs: dict) -> bool:\n",
    "    \"\"\"Check if the answer exactly matches the expected answer.\"\"\"\n",
    "    return outputs[\"classification_decision\"].lower() == reference_outputs[\"classification\"].lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348315e4",
   "metadata": {},
   "source": [
    "### å¼€å§‹æµ‹è¯•\n",
    "\n",
    "å½“æˆ‘ä»¬å®šä¹‰å¥½æ‰€éœ€è¦çš„å‡½æ•°åï¼Œæ€ä¹ˆå°†ä»–ä»¬ä¸²è”èµ·æ¥è¿›è¡Œæµ‹è¯•å‘¢ï¼Ÿç­”æ¡ˆå¾ˆç®€å•ï¼š`evaluate` å‡½æ•°ä¼šå¸®æˆ‘ä»¬å®Œæˆè¿™äº›ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00d4048a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhengquan/miniconda3/envs/agents-course/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'E-mail assistant workflow-25fd6e5b' at:\n",
      "https://smith.langchain.com/o/705cd733-208b-5894-8174-4d8f8d81a26f/datasets/047df233-6b46-4a77-82bb-9c2310c0b3d5/compare?selectedSessions=65812575-abc5-415a-b85e-34cad2be3ff7\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš« Classification: IGNORE - This email can be safely ignored\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“§ Classification: RESPOND - This email requires a response\n",
      "ğŸ“§ Classification: RESPOND - This email requires a response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:04,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”” Classification: NOTIFY - This email contains important information\n",
      "ğŸ“§ Classification: RESPOND - This email requires a response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:06,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“§ Classification: RESPOND - This email requires a response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:06,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš« Classification: IGNORE - This email can be safely ignored\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:08,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“§ Classification: RESPOND - This email requires a response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:09,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”” Classification: NOTIFY - This email contains important information\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:09,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”” Classification: NOTIFY - This email contains important information\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:13,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“§ Classification: RESPOND - This email requires a response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:14,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“§ Classification: RESPOND - This email requires a response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:15,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš« Classification: IGNORE - This email can be safely ignored\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:15,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš« Classification: IGNORE - This email can be safely ignored\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:16,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”” Classification: NOTIFY - This email contains important information\n",
      "ğŸ”” Classification: NOTIFY - This email contains important information\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:17,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "run_expt = True # set to true if you want to run the experiment\n",
    "if run_expt:\n",
    "    experiment_results_workflow = client.evaluate(\n",
    "        target_email_assistant, # run agent\n",
    "        data=dataset_name, # dataset name\n",
    "        evaluators=[\n",
    "            classification_evaluator\n",
    "        ],\n",
    "        experiment_prefix=\"E-mail assistant workflow\", # name of the experiment\n",
    "        max_concurrency=2, # number of concurrent evaluations\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b78276",
   "metadata": {},
   "source": [
    "æ‰§è¡Œç»“æŸåï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ LangSmith UI ä¸­æŸ¥çœ‹ç»“æœã€‚\n",
    "\n",
    "![æµ‹è¯•ç»“æœ](img/04_langsmith_dataset_eval_result.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e74f54",
   "metadata": {},
   "source": [
    "## LLM-as-Judge Evaluation\n",
    "\n",
    "ä¸Šé¢ä¸¤ä¸ªéƒ¨åˆ†ï¼Œæˆ‘ä»¬åˆ†åˆ«ä½¿ç”¨ `Pytest` æµ‹è¯•äº†å·¥å…·è°ƒç”¨çš„æ•ˆæœï¼Œä½¿ç”¨ LangSmith `evaluate()` æµ‹è¯•äº†é‚®ä»¶åˆ†ç±»çš„æ•ˆæœã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œè¿™ä¸¤éƒ¨åˆ†éƒ½å±äºå•å…ƒæµ‹è¯•ï¼ˆUnit Testï¼‰ï¼Œä¸”éƒ½æœ‰ç€ç»“æ„åŒ–çš„æ ‡å‡†ç»“æœã€‚\n",
    "\n",
    "![æµ‹è¯•åˆ†ç±»](img/eval_types.png)\n",
    "\n",
    "æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è¦è¿›è¡Œæ•´ä¸ª email assistant çš„æœ€ç»ˆè¾“å‡ºç»“æœæµ‹è¯•ï¼Œä»–æ˜¯ä¸€ä¸ªå…¸å‹çš„ç«¯åˆ°ç«¯ï¼ˆEnd-to-End, E2Eï¼‰æµ‹è¯•ï¼Œå°†æ‰€æœ‰çš„è¿‡ç¨‹å’Œç»“æœéƒ½æ¦‚æ‹¬åœ¨ä¸€èµ·è¿›è¡Œè¯„ä¼°ã€‚\n",
    "\n",
    "å› ä¸º agent çš„æœ€ç»ˆè¾“å‡ºçš„é‚®ä»¶å†…å®¹ä¸å›ºå®šçš„ï¼Œæ‰€ä»¥æ— æ³•åƒä¹‹å‰é‚£æ ·è¿›è¡Œç»“æ„åŒ–çš„æµ‹è¯•ã€‚\n",
    "\n",
    "æµ‹è¯•éç»“æ„åŒ–çš„è¾“å‡ºï¼Œé™¤äº†äººä¸ºçš„å»åˆ¤æ–­å¤–ï¼Œç°åœ¨æœ€å¸¸ç”¨çš„æ–¹æ³•å°±æ˜¯ä½¿ç”¨ LLM ä½œä¸ºè£åˆ¤æ¥è¿›è¡Œè¯„åˆ¤ã€‚ä¸‹é¢å°†ä»‹ç»å…·ä½“æ€ä¹ˆåšã€‚\n",
    "\n",
    "é¦–å…ˆï¼Œéœ€è¦å®šä¹‰ä¸€ä¸ªç»“æ„åŒ–çš„è¾“å‡ºç”¨äºå¤„ç† LLM çš„è¯„ä»·ç»“æœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89d3ee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "class CriteriaGrade(BaseModel):\n",
    "    \"\"\"Score the response against specific criteria.\"\"\"\n",
    "\n",
    "    justification: str = Field(description=\"The justification for the grade and score, including specifict examples from the response.\")\n",
    "    grade: bool = Field(description=\"Dose the resonse meet the provided criteria?\")\n",
    "\n",
    "# Create a global LLM for evaluation to avoid recreate it for each test\n",
    "model_name = os.getenv(\"OPENAI_MODEL\")\n",
    "model_provider = os.getenv(\"MODEL_PROVIDER\")\n",
    "criteria_eval_llm = init_chat_model(model_name, model_provider=model_provider)\n",
    "criteria_eval_structured_llm = criteria_eval_llm.with_structured_output(CriteriaGrade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83d4abab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email Input: {'author': 'Alice Smith <alice.smith@company.com>', 'to': 'Lance Martin <lance@company.com>', 'subject': 'Quick question about API documentation', 'email_thread': \"Hi Lance,\\n\\nI was reviewing the API documentation for the new authentication service and noticed a few endpoints seem to be missing from the specs. Could you help clarify if this was intentional or if we should update the docs?\\n\\nSpecifically, I'm looking at:\\n- /auth/refresh\\n- /auth/validate\\n\\nThanks!\\nAlice\"}\n",
      "Success Criteria: \n",
      "â€¢ Send email with write_email tool call to acknowledge the question and confirm it will be investigated  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.eval.email_dataset import email_inputs, response_criteria_list\n",
    "\n",
    "email_input = email_inputs[0]\n",
    "print(\"Email Input:\", email_input)\n",
    "success_criteria = response_criteria_list[0]\n",
    "print(\"Success Criteria:\", success_criteria)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032b8d68",
   "metadata": {},
   "source": [
    "æŸ¥çœ‹å…¶ä¸­ä¸€æ¡æ•°æ®ï¼š\n",
    "```\n",
    "Success Criteria: \n",
    "â€¢ Send email with write_email tool call to acknowledge the question and confirm it will be investigated  \n",
    "```\n",
    "æˆ‘ä»¬ä¼šå‘ç°ï¼Œè¿™ä¸ªè¯„ä»·æ ‡å‡†æ˜¯éå¸¸å£è¯­åŒ–çš„ï¼Œå¹¶ä¸”åŒ…å«äº†éœ€è¦è°ƒç”¨çš„å·¥å…·ï¼Œå¾ˆéš¾ç”¨å›ºå®šçš„è§„åˆ™æ¥å®ç°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89754031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“§ Classification: RESPOND - This email requires a response\n"
     ]
    }
   ],
   "source": [
    "response = email_assistant.invoke({\"email_input\": email_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d689c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are evaluating an email assistant that works on behalf of a user.\n",
      "\n",
      "You will see a sequence of messages, starting with an email sent to the user. \n",
      "\n",
      "You will then see the assistant's response to this email on behalf of the user, which includes any tool calls made (e.g., write_email, schedule_meeting, check_calendar_availability, done).\n",
      "\n",
      "You will also see a list of criteria that the assistant's response must meet.\n",
      "\n",
      "Your job is to evaluate if the assistant's response meets ALL the criteria bullet points provided.\n",
      "\n",
      "IMPORTANT EVALUATION INSTRUCTIONS:\n",
      "1. The assistant's response is formatted as a list of messages.\n",
      "2. The response criteria are formatted as bullet points (â€¢)\n",
      "3. You must evaluate the response against EACH bullet point individually\n",
      "4. ALL bullet points must be met for the response to receive a 'True' grade\n",
      "5. For each bullet point, cite specific text from the response that satisfies or fails to satisfy it\n",
      "6. Be objective and rigorous in your evaluation\n",
      "7. In your justification, clearly indicate which criteria were met and which were not\n",
      "7. If ANY criteria are not met, the overall grade must be 'False'\n",
      "\n",
      "Your output will be used for automated testing, so maintain a consistent evaluation approach.\n"
     ]
    }
   ],
   "source": [
    "from src.eval.prompts import RESPONSE_CRITERIA_SYSTEM_PROMPT\n",
    "\n",
    "# Format the messages into a string for evaluation\n",
    "all_messages_str = format_messages_string(response[\"messages\"])\n",
    "\n",
    "print(RESPONSE_CRITERIA_SYSTEM_PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b41134",
   "metadata": {},
   "source": [
    "`RESPONSE_CRITERIA_SYSTEM_PROMPT` ä¸­è¯´æ˜äº†è¿™ä¸ª llm evaluator çš„å·¥ä½œæ–¹å¼ã€‚\n",
    "\n",
    "ä¸‹é¢çš„ user prompt ä¸­ä¼šæŒ‡æ˜å½“å‰çš„è¿™æ¡æ•°æ®æ‰€è¦æ»¡è¶³çš„æ ‡å‡†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde7decf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = criteria_eval_structured_llm.invoke(\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": RESPONSE_CRITERIA_SYSTEM_PROMPT},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"Response criteria: {success_criteria} \\n\\n Assistant's response: {all_messages_str} \\n\\n Evaluate whether the assistant's response meets the criteria and provide justification for your evaluation.\"\"\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b57840",
   "metadata": {},
   "source": [
    "æ‰§è¡Œå®Œä»£ç ï¼Œä¼šè·å–åˆ°ä¸€ä¸ª `CriteriaGrade` å¯¹è±¡ï¼Œé‡Œé¢åŒ…å«äº†è¯„ä¼°è¿‡ç¨‹å’Œæœ€åçš„ç»“æœã€‚å¦‚æœ `grade` ä¸º Trueï¼Œåˆ™è¡¨ç¤ºè¯„ä¼°é€šè¿‡ï¼Œå¦åˆ™è¡¨ç¤ºè¯„ä¼°æœªé€šè¿‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c6453d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€¢ The assistant sent an email using the write_email tool call, as shown in the \"Tool Calls:\" section. The call includes the recipient's email (alice.smith@company.com), subject (Re: Quick question about API documentation), and content that acknowledges Alice's question and confirms that the issue will be investigated. This meets the criteria of sending an email to acknowledge the question and confirm it will be investigated.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(eval_result.justification)\n",
    "print(eval_result.grade)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675b3197",
   "metadata": {},
   "source": [
    "## æ›´å®Œæ•´çš„è¯„ä¼°\n",
    "\n",
    "ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å·²ç»å°è¯•äº†ï¼š\n",
    "- Pytest å•å…ƒæµ‹è¯•\n",
    "- LangSmith `evaluate()` å•å…ƒæµ‹è¯•\n",
    "- LLM as a judge ç«¯åˆ°ç«¯æµ‹è¯•\n",
    "\n",
    "æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è¦æŠŠè¿™äº›å†…å®¹æ•´ç†åˆ°ä¸€èµ·ï¼Œè¿›è¡Œæ›´å…¨é¢ã€æ›´ä¸°å¯Œçš„è¯„ä¼°ã€‚è¿™éƒ¨åˆ†è¯„ä¼°ä»£ç å·²ç»æ•´ç†åˆ°äº† `tests/test_response.py` ä¸­ï¼Œæˆ‘ä»¬æ¥è¿è¡Œä¸€ä¸‹çœ‹çœ‹æ•ˆæœã€‚\n",
    "\n",
    "åˆ‡æ¢åˆ° `tests` ç›®å½•ï¼Œæ‰§è¡Œå‘½ä»¤ï¼š\n",
    "```bash\n",
    "LANGSMITH_TEST_SUITE='04 Email assistant: Test Full Response Interrupt' LANGSMITH_EXPERIMENT='email_assistant' pytest test_response.py --agent-module email_assistant\n",
    "```\n",
    "å…¶ä¸­ï¼š\n",
    "- `LANGSMITH_TEST_SUITE`ï¼šLangSmith ä¸­çš„æµ‹è¯•æ•°æ®é›†çš„åç§°\n",
    "- `LANGSMITH_EXPERIMENT`ï¼šLangSmith ä¸­çš„å®éªŒåç§°\n",
    "\n",
    "æ•´ä¸ª `test_response.py` æ˜¯ä½¿ç”¨ `Pytest` çš„æ–¹æ³•è¿›è¡Œçš„ï¼Œè£…é¥°å™¨ä¸­çš„æµ‹è¯•ç”¨ä¾‹ä¼šè‡ªåŠ¨ä¸Šä¼ åˆ° LangSmith ä¸­ï¼Œå¹¶åˆ›å»ºåç§°ä¸º `LANGSMITH_TEST_SUITE` çš„æ•°æ®é›†ã€‚\n",
    "\n",
    "åœ¨ `test_response.py` ä¸­ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸¤ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼š\n",
    "- `test_email_dataset_tool_calls`ï¼šæµ‹è¯•é‚®ä»¶å¤„ç†æ˜¯å¦åŒ…å«é¢„æœŸçš„å·¥å…·è°ƒç”¨\n",
    "- `test_response_criteria_evaluation`ï¼šæµ‹è¯•å“åº”æ˜¯å¦æ»¡è¶³ç‰¹å®šæ ‡å‡†ï¼Œå…¶ä¸­åŒ…å«äº† LLM-as-a-judge çš„å†…å®¹\n",
    "\n",
    "\n",
    "è„šæœ¬æ‰§è¡Œå®Œæˆä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ LangSmith UI ä¸Šçœ‹åˆ°æ‰§è¡Œç»“æœã€‚\n",
    "![å®Œæ•´æµ‹è¯•ç»“æœ](./img/04_full_test_result.png)\n",
    "\n",
    "åŒæ—¶ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥é€šè¿‡ SDK æ¥è·å–ç»“æœåˆ°æœ¬åœ°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd8b64ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency p50: 0:00:11.443000\n",
      "Latency p99: 0:00:24.026950\n",
      "Token Usage: 67435\n",
      "Feedback Stats: {'pass': {'n': 16, 'avg': 0.6875, 'stdev': 0.46351240544347894, 'errors': 0, 'values': {}}}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Copy your experiment name here\n",
    "experiment_name = \"email_assistant:0346f18c\"\n",
    "# Set this to load expt results\n",
    "load_expt = True\n",
    "if load_expt:\n",
    "    email_assistant_experiment_results = client.read_project(project_name=experiment_name, include_stats=True)\n",
    "    print(\"Latency p50:\", email_assistant_experiment_results.latency_p50)\n",
    "    print(\"Latency p99:\", email_assistant_experiment_results.latency_p99)\n",
    "    print(\"Token Usage:\", email_assistant_experiment_results.total_tokens)\n",
    "    print(\"Feedback Stats:\", email_assistant_experiment_results.feedback_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a95aaf",
   "metadata": {},
   "source": [
    "ä¸Šè¿°ä»£ç ä¸­ï¼Œéœ€è¦æ³¨æ„å‡ ç‚¹ï¼š\n",
    "- `experiment_name` éœ€è¦ä½ ä» UI ä¸Š copy ä¸‹æ¥ï¼›\n",
    "- `experiment_name` çš„å€¼ \"email_assistant:0346f18c\" çš„å‰ç¼€å°±æ˜¯è¿è¡Œæµ‹è¯•å‘½ä»¤æ—¶è®¾ç½®çš„ç¯å¢ƒå˜é‡ `LANGSMITH_EXPERIMENT` çš„å€¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
